ðŸ“‚ web-scraping-preprocessing
â”‚â”€â”€ ðŸ“‚ data
â”‚   â”œâ”€â”€ raw_papers.csv             # Data mentah hasil scraping
â”‚   â”œâ”€â”€ cleaned_papers.csv         # Data setelah preprocessing
â”‚   â”œâ”€â”€ final_papers.csv           # Data final setelah preprocessing dan filtering
â”‚
â”‚â”€â”€ ðŸ“‚ notebooks
â”‚   â”œâ”€â”€ scraping.ipynb             # Notebook untuk proses scraping
â”‚   â”œâ”€â”€ preprocessing.ipynb        # Notebook untuk preprocessing teks
â”‚   â”œâ”€â”€ topic_modeling.ipynb       # Notebook untuk analisis topik menggunakan LDA
â”‚
â”‚â”€â”€ ðŸ“‚ scripts
â”‚   â”œâ”€â”€ main.py                    # Skrip utama yang menjalankan semua proses
â”‚   â”œâ”€â”€ scraper.py                  # Skrip untuk scraping data dari Google Scholar
â”‚   â”œâ”€â”€ preprocess.py               # Skrip untuk membersihkan data teks
â”‚   â”œâ”€â”€ utils.py                    # Skrip helper (fungsi-fungsi pendukung)
â”‚
â”‚â”€â”€ ðŸ“‚ models
â”‚   â”œâ”€â”€ lda_model.pkl               # Model LDA yang telah dilatih
â”‚   â”œâ”€â”€ vectorizer.pkl              # Model vectorizer (TF-IDF/CountVectorizer)
â”‚
â”‚â”€â”€ ðŸ“‚ logs
â”‚   â”œâ”€â”€ scraping.log                # Log dari proses scraping
â”‚   â”œâ”€â”€ preprocessing.log           # Log dari proses preprocessing
â”‚
â”‚â”€â”€ ðŸ“‚ results
â”‚   â”œâ”€â”€ topic_distribution.png      # Grafik distribusi topik hasil LDA
â”‚   â”œâ”€â”€ wordcloud.png               # Wordcloud dari hasil topik
â”‚
â”‚â”€â”€ .gitignore                      # File untuk mengabaikan file tertentu di Git
â”‚â”€â”€ requirements.txt                 # Daftar dependensi Python yang diperlukan
â”‚â”€â”€ README.md                        # Dokumentasi proyek
